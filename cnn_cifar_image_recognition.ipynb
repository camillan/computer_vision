{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPPPfjEdT0f2MAlIDidnnSe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/camillan/computer_vision/blob/main/cnn_cifar_image_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "8PR-s2dc9Yj1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Bcu_YTmw8XcZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# convert images to tensors and normalize pixel values\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(), # converts to tensor\n",
        "     transforms.Normalize((0.5,), (0.5,))]) # normalizes the RGB values\n",
        "\n",
        "# load cifar-10\n",
        "# train\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data',\n",
        "                                        train=True,\n",
        "                                        download=True,\n",
        "                                        transform=transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=False)\n",
        "\n",
        "# test\n",
        "testset = torchvision.datasets.CIFAR10(root='./data',\n",
        "                                       train=False,\n",
        "                                       download=True,\n",
        "                                       transform=transform)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
        "\n",
        "# classes that are potential labels in CIFAR-10\n",
        "classes = trainset.classes"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define CNN"
      ],
      "metadata": {
        "id": "98p3xyLg9bmv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# define simple CNN with 2 convolutional layers and 2 fully connected layers\n",
        "class SimpleCNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(SimpleCNN, self).__init__()\n",
        "\n",
        "    # first conv layer 3 input channels (RGB), output = 32 filters, kernel = 3x3\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
        "\n",
        "    # second conv layer\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "\n",
        "    # max pooking layer to downsample feature maps by 2x\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    # fully connected layer - flatten from 64x8x8 to 128\n",
        "    self.fc1 = nn.Linear(in_features=64*8*8, out_features=128)\n",
        "\n",
        "    # output layer has 10 classes for CIFAR-10\n",
        "    self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # apply first conv -> ReLU -> pooling -> output shape\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "\n",
        "    # apply second conv -> ReLU -> pooling -> output shape\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "\n",
        "    # flatten 3d feature maps to 1d vector per image\n",
        "    x = x.view(-1, 64*8*8)\n",
        "\n",
        "    # fully connected layer -> ReLU\n",
        "    x = F.relu(self.fc1(x))\n",
        "\n",
        "    # final layer -> class scores as logits\n",
        "    x = self.fc2(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "# instatiate the model\n",
        "model = SimpleCNN()\n"
      ],
      "metadata": {
        "id": "ZfsvNVXL9SAA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup training loop"
      ],
      "metadata": {
        "id": "pwkLrDfnGLD9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# define the loss function (cross entropy for multi class classification)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# define the optimizer (adam optimizer)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# training loop for 5 epochs\n",
        "for epoch in range(5):\n",
        "  # track loss for this epoch\n",
        "  running_loss = 0.0\n",
        "\n",
        "  for images, labels in trainloader:\n",
        "    # make zero the gradients from previous step\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # forward pass: compute predicted outputs\n",
        "    outputs = model(images)\n",
        "\n",
        "    # compute loss between predicted and true labels\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # backward pass: compute gradients\n",
        "    loss.backward()\n",
        "\n",
        "    # update weights\n",
        "    optimizer.step()\n",
        "\n",
        "    # accumulate loss\n",
        "    running_loss += loss.item()\n",
        "\n",
        "  # print average loss per epoch\n",
        "  print(f\"Epoch {epoch+1}, Loss: {running_loss/len(trainloader):.4f}\")\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Nun-ZsYFIok",
        "outputId": "49d9501c-0e0a-4342-c0a3-58344a4de101"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.3529\n",
            "Epoch 2, Loss: 0.9686\n",
            "Epoch 3, Loss: 0.8053\n",
            "Epoch 4, Loss: 0.6837\n",
            "Epoch 5, Loss: 0.5796\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate on test set"
      ],
      "metadata": {
        "id": "Nh5w7-IqHSjb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# don't compute gradients during evaluation (only happens during training)\n",
        "with torch.no_grad():\n",
        "  for images, labels in testloader:\n",
        "    outputs = model(images)\n",
        "\n",
        "    # get predicted class with highest score\n",
        "    _, predicted = torch.max(outputs, dim=1)\n",
        "\n",
        "    # count correct predictions\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "# print overall accuracy\n",
        "print(f\"Test accuracy: {100 * correct/total:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVuX71e1HRnf",
        "outputId": "94c5f894-b455-4d3c-a26d-8b195f57c488"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 71.18%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NmYW2ynZIExP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}